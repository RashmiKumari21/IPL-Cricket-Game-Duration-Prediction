{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Name - Write_To_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function writes the output dataframes to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_To_CSV(Delivery_DF, Match_DF, path):\n",
    "    Delivery_DF = Delivery_DF.drop(columns=['Match_ID'])\n",
    "    Delivery_DF.index.name='Match_ID'\n",
    "    Match_DF.index.name='Match_ID'\n",
    "    Delivery_DF.to_csv(path+'Delivery_Info.csv')\n",
    "    Match_DF.to_csv(path+'Match_Info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Name - Yaml_Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds all the YAML file at the input directory path. Then reads the file one at a time and parse the data into a pandas data frame. After parsing the datas from the YAML file into a pandas dataframe, it returns the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yaml_Reader(dir_path):\n",
    "    pool = ThreadPool(processes=1)\n",
    "    CSV_Data_Deliveries = pd.DataFrame()\n",
    "    CSV_Match_Info = pd.DataFrame()\n",
    "    \n",
    "    path_list = glob.glob(dir_path+\"*.yaml\")\n",
    "    ID = 1\n",
    "    for path in path_list:\n",
    "        with open(path, 'r') as file_object:\n",
    "            try:\n",
    "                print (ID,'------>',path)\n",
    "                data = yaml.safe_load(file_object)\n",
    "                t1 = pool.apply_async(Data_Extractor, (data, ID))\n",
    "                t2 = pool.apply_async(Match_Info, (data, ID))\n",
    "                CSV_Data_Deliveries = pd.concat([CSV_Data_Deliveries, t1.get()])\n",
    "                CSV_Match_Info = pd.concat([CSV_Match_Info, t2.get()])\n",
    "                ID = ID + 1\n",
    "            except yaml.YAMLError as exc:\n",
    "                print (exc)\n",
    "                \n",
    "    return CSV_Data_Deliveries, CSV_Match_Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Name - Match_Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes three inputs and gives a pandas dataframe as output. A dctionary containing the data, a dataframe that will contain the extracted data and ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_Info(data, ID):\n",
    "    DataFrame = pd.DataFrame()\n",
    "    info = data['info']\n",
    "    date_data = info['dates'][0] if type(info['dates'][0]) != str else datetime.strptime(info['dates'][0], '%Y-%m-%d').date()\n",
    "    season = date_data.year\n",
    "    date = date_data.strftime(\"%m/%d/%y\")\n",
    "    team1 = info['teams'][0]\n",
    "    team2 = info['teams'][1]\n",
    "    toss_winner = info['toss']['winner']\n",
    "    toss_decision = info['toss']['decision']\n",
    "    result = info['outcome']['result'] if 'result' in info['outcome'] else 'Normal'\n",
    "    dl_applied = 1 if 'method' in info['outcome'] else 0\n",
    "    winning_data = info['outcome']['by'] if 'by' in info['outcome'] else info['outcome']\n",
    "    winner = info['outcome']['winner'] if 'winner' in info['outcome'] else None\n",
    "    win_by_runs = winning_data['runs'] if 'runs' in winning_data else None\n",
    "    win_by_wicket = winning_data['wickets'] if 'wickets' in winning_data else None\n",
    "    man_of_the_match = info['player_of_match'] if 'player_of_match' in info else None\n",
    "    venue = info['venue'] \n",
    "    umpires = info['umpires']\n",
    "    umpire1 = umpires[0] if len(umpires) > 0 else None\n",
    "    umpire2 = umpires[1] if len(umpires) > 0 else None\n",
    "    umpire3 = umpires[2] if len(umpires) == 3 else None\n",
    "    \n",
    "    Match_Data = {'Season' : season,\n",
    "                  'Date' : date,\n",
    "                  'Team1' : team1,\n",
    "                  'Team2' : team2,\n",
    "                  'Toss_Winner' : toss_winner,\n",
    "                  'Toss_Decision' : toss_decision, \n",
    "                  'Result' : result,\n",
    "                  'DL_Method' : dl_applied,\n",
    "                  'Winner' : winner,\n",
    "                  'Win_By_Runs' : win_by_runs,\n",
    "                  'Win_By_Wicket' : win_by_wicket,\n",
    "                  'Man_Of_The_Match' : man_of_the_match,\n",
    "                  'Venue' : venue,\n",
    "                  'Umpire1' : umpire1,\n",
    "                  'Umpire2' : umpire2,\n",
    "                  'Umpire3' : umpire3,\n",
    "                 }\n",
    "    \n",
    "    row = pd.DataFrame(Match_Data, index=[ID])\n",
    "    DataFrame = pd.concat([DataFrame,row])\n",
    "    \n",
    "    return DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Name - Data_Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes data a dictionary, a pandas dataframe and ID. Then parse the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Extractor(data, ID):\n",
    "    DataFrame = pd.DataFrame()\n",
    "    number_of_innings = len(data['innings'])\n",
    "    super_over = 1 if len(data['innings']) == 4 else 0\n",
    "    teams = np.array(data['info']['teams'])\n",
    "\n",
    "    for i in range(0, number_of_innings):\n",
    "        innings_number = [*data['innings'][i]][0]\n",
    "        batting_team = data['innings'][i][innings_number]['team']\n",
    "        bowling_team = teams[teams!=batting_team]\n",
    "        innings_data = data['innings'][i][innings_number]['deliveries']\n",
    "        for j in range(0,len(innings_data)):\n",
    "            over_data = [*innings_data[j]][0]\n",
    "            over = int(over_data)+1\n",
    "            ball = int(str(over_data-int(over_data))[2])\n",
    "            batsman = innings_data[j][over_data]['batsman']\n",
    "            non_striker = innings_data[j][over_data]['non_striker']\n",
    "            bowler = innings_data[j][over_data]['bowler']\n",
    "            runs = innings_data[j][over_data]['runs']\n",
    "            batsman_run = runs['batsman']\n",
    "            extra_runs = runs['extras']\n",
    "            total_runs = runs['total']\n",
    "\n",
    "            if 'extras' in innings_data[j][over_data]:\n",
    "                extras = innings_data[j][over_data]['extras']\n",
    "                wides = extras['wides'] if 'wides' in extras else 0\n",
    "                bye_runs = extras['bye_runs'] if 'bye_runs' in extras else 0\n",
    "                legbye_runs = extras['legbye_runs'] if 'legbye_runs' in extras else 0\n",
    "                noball_runs = extras['noball_runs'] if 'noball_runs' in extras else 0\n",
    "                penalty_runs = extras['penalty_runs'] if 'penalty_runs' in extras else 0\n",
    "            else:\n",
    "                wides = 0\n",
    "                bye_runs = 0\n",
    "                legbye_runs = 0\n",
    "                noball_runs = 0\n",
    "                penalty_runs = 0\n",
    "\n",
    "            if 'wicket' in innings_data[j][over_data]:\n",
    "                wicket_data = innings_data[j][over_data]['wicket']\n",
    "                player_dismissed = wicket_data['player_out']\n",
    "                dismissal_type = wicket_data['kind']\n",
    "                if 'fielders' in wicket_data:   # If there are more than one filder involved then select the 1st filder\n",
    "                    fielder = wicket_data['fielders']\n",
    "                    fielder = fielder[0] if len(fielder) > 1 else fielder\n",
    "                else:\n",
    "                    fielder = None\n",
    "                \n",
    "            else:\n",
    "                player_dismissed = None\n",
    "                dismissal_type = None\n",
    "                fielder = None\n",
    "\n",
    "            ball_by_ball_data = {'Innings' : i+1,\n",
    "                                 'Batting_Team' : batting_team,\n",
    "                                 'Bowling_Team' : bowling_team,\n",
    "                                 'Over' : over,\n",
    "                                 'Ball' : ball,\n",
    "                                 'Batsman' : batsman,\n",
    "                                 'Non_Striker' : non_striker,\n",
    "                                 'Bowler' : bowler,\n",
    "                                 'Is_Super_Over' : super_over,\n",
    "                                 'Wide_Runs' : wides,\n",
    "                                 'Bye_Runs' : bye_runs,\n",
    "                                 'Legbye_Runs' : legbye_runs,\n",
    "                                 'Noball_Runs' : noball_runs,\n",
    "                                 'Penalty_Runs' : penalty_runs,\n",
    "                                 'Batsman_Runs' : batsman_run,\n",
    "                                 'Extras' : extra_runs,\n",
    "                                 'Total_Runs' : total_runs,\n",
    "                                 'Player_Dismissed' : player_dismissed,\n",
    "                                 'Dismissal_Type' : dismissal_type,\n",
    "                                 'Fielder' : fielder\n",
    "                                }\n",
    "            row = pd.DataFrame(ball_by_ball_data,index=[ID])\n",
    "            DataFrame = pd.concat([DataFrame,row])\n",
    "    \n",
    "    return DataFrame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Yaml_Reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96c2aea7e42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCSV_Delivery_Info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSV_Match_Info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYaml_Reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/swayam/Documents/Projects/ipl/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Give the path of the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                                 \u001b[0;31m#containing YAML files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mWrite_To_CSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_Delivery_Info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSV_Match_Info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/swayam/Documents/Projects/Data_Mining/Data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Give path of the directory where\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                  \u001b[0;31m# you want to save the output CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Yaml_Reader' is not defined"
     ]
    }
   ],
   "source": [
    "CSV_Delivery_Info, CSV_Match_Info = Yaml_Reader('/Users/swayam/Documents/Projects/ipl/') # Give the path of the directory \n",
    "                                                                                #containing YAML files\n",
    "Write_To_CSV(CSV_Delivery_Info, CSV_Match_Info, '/Users/swayam/Documents/Projects/Data_Mining/Data') # Give path of the directory where\n",
    "                                                                                 # you want to save the output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Delivery_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Delivery_Info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Match_Info.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
